Epoch 1/300:   0%|          | 0/126 [00:00<?, ?batch/s]Epoch 1/300:   0%|          | 0/126 [00:00<?, ?batch/s]/work/cvcs_2023_group23/AIB_new/AIB_env/lib/python3.9/site-packages/albumentations/augmentations/functional.py:981: RuntimeWarning: invalid value encountered in power
  return np.power(img, gamma)
/work/cvcs_2023_group23/AIB_new/AIB_env/lib/python3.9/site-packages/albumentations/augmentations/functional.py:981: RuntimeWarning: invalid value encountered in power
  return np.power(img, gamma)
/work/cvcs_2023_group23/AIB_new/AIB/train_crop.py:301: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly(): #for debug only
/work/cvcs_2023_group23/AIB_new/AIB/train_crop.py:301: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with torch.autograd.detect_anomaly(): #for debug only
/work/cvcs_2023_group23/AIB_new/AIB_env/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Error detected in LogSoftmaxBackward0. No forward pass information available. Enable detect anomaly during forward pass for more information. (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:92.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/work/cvcs_2023_group23/AIB_new/AIB_env/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Error detected in LogSoftmaxBackward0. No forward pass information available. Enable detect anomaly during forward pass for more information. (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:92.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch 1/300:   0%|          | 0/126 [00:38<?, ?batch/s]
Epoch 1/300:   0%|          | 0/126 [00:38<?, ?batch/s]
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1006961 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -9) local_rank: 0 (pid: 1006960) of binary: /work/cvcs_2023_group23/AIB_new/AIB_env/bin/python
Traceback (most recent call last):
  File "/work/cvcs_2023_group23/AIB_new/AIB_env/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/work/cvcs_2023_group23/AIB_new/AIB_env/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/work/cvcs_2023_group23/AIB_new/AIB_env/lib/python3.9/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/work/cvcs_2023_group23/AIB_new/AIB_env/lib/python3.9/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/work/cvcs_2023_group23/AIB_new/AIB_env/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/work/cvcs_2023_group23/AIB_new/AIB_env/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
eval_crop.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-10-31_19:44:30
  host      : nico.ing.unimo.it
  rank      : 0 (local_rank: 0)
  exitcode  : -9 (pid: 1006960)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 1006960
========================================================
slurmstepd: error: Detected 1 oom_kill event in StepId=2478168.batch. Some of the step tasks have been OOM Killed.
