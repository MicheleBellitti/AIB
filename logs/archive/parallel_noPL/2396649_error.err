/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[E socket.cpp:793] [c10d] The client socket has timed out after 1800s while trying to connect to (localhost, 12355).
[E socket.cpp:793] [c10d] The client socket has timed out after 1800s while trying to connect to (localhost, 12355).
[E socket.cpp:793] [c10d] The client socket has timed out after 1800s while trying to connect to (localhost, 12355).
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/work/cvcs_2023_group23/AIB/train.py", line 154, in <module>
  File "/work/cvcs_2023_group23/AIB/train.py", line 154, in <module>
  File "/work/cvcs_2023_group23/AIB/train.py", line 154, in <module>
        mp.spawn(train, args=(world_size, 50, start_epoch, train_loader, simclr_model, optimizer, get_simclr_augmentation_pipeline(), get_simclr_augmentation_pipeline(type=2), temperature, checkpoint_dir), nprocs=world_size, join=True)    mp.spawn(train, args=(world_size, 50, start_epoch, train_loader, simclr_model, optimizer, get_simclr_augmentation_pipeline(), get_simclr_augmentation_pipeline(type=2), temperature, checkpoint_dir), nprocs=world_size, join=True)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
mp.spawn(train, args=(world_size, 50, start_epoch, train_loader, simclr_model, optimizer, get_simclr_augmentation_pipeline(), get_simclr_augmentation_pipeline(type=2), temperature, checkpoint_dir), nprocs=world_size, join=True)

  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes


  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
      File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    while not context.join():while not context.join():

    raise ProcessRaisedException(msg, error_index, failed_process.pid)  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 160, in join
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 160, in join

torch.multiprocessing.spawn.    ProcessRaisedException:     raise ProcessRaisedException(msg, error_index, failed_process.pid)raise ProcessRaisedException(msg, error_index, failed_process.pid)

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/work/cvcs_2023_group23/AIB/train.py", line 111, in train
    setup(rank, world_size)
  File "/work/cvcs_2023_group23/AIB/train.py", line 20, in setup
    dist.init_process_group("nccl", rank=rank, world_size=world_size)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 595, in init_process_group
    store, rank, world_size = next(rendezvous_iterator)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/rendezvous.py", line 257, in _env_rendezvous_handler
    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/rendezvous.py", line 184, in _create_c10d_store
    tcp_store = TCPStore(hostname, port, world_size, False, timeout)
TimeoutError: The client socket has timed out after 1800s while trying to connect to (localhost, 12355).



torch.multiprocessing.spawntorch.multiprocessing.spawn..ProcessRaisedExceptionProcessRaisedException: : 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/work/cvcs_2023_group23/AIB/train.py", line 111, in train
    setup(rank, world_size)
  File "/work/cvcs_2023_group23/AIB/train.py", line 20, in setup
    dist.init_process_group("nccl", rank=rank, world_size=world_size)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 595, in init_process_group
    store, rank, world_size = next(rendezvous_iterator)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/rendezvous.py", line 257, in _env_rendezvous_handler
    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/rendezvous.py", line 184, in _create_c10d_store
    tcp_store = TCPStore(hostname, port, world_size, False, timeout)
TimeoutError: The client socket has timed out after 1800s while trying to connect to (localhost, 12355).


-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/work/cvcs_2023_group23/AIB/train.py", line 111, in train
    setup(rank, world_size)
  File "/work/cvcs_2023_group23/AIB/train.py", line 20, in setup
    dist.init_process_group("nccl", rank=rank, world_size=world_size)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 595, in init_process_group
    store, rank, world_size = next(rendezvous_iterator)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/rendezvous.py", line 257, in _env_rendezvous_handler
    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/rendezvous.py", line 184, in _create_c10d_store
    tcp_store = TCPStore(hostname, port, world_size, False, timeout)
TimeoutError: The client socket has timed out after 1800s while trying to connect to (localhost, 12355).


ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 2838843) of binary: /work/cvcs_2023_group23/AIB/AIB_env/bin/python
Traceback (most recent call last):
  File "/usr/local/anaconda3/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/local/anaconda3/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-06-25_18:51:56
  host      : ajeje.ing.unimore.it
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 2838847)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-06-25_18:51:56
  host      : ajeje.ing.unimore.it
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 2838848)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-25_18:51:56
  host      : ajeje.ing.unimore.it
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2838843)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 2845244 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 2845245 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -9) local_rank: 2 (pid: 2845246) of binary: /work/cvcs_2023_group23/AIB/AIB_env/bin/python
Traceback (most recent call last):
  File "/usr/local/anaconda3/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/local/anaconda3/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/work/cvcs_2023_group23/AIB/AIB_env/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
eval.py FAILED
--------------------------------------------------------
Failures:
[1]:
  time      : 2024-06-25_18:53:54
  host      : ajeje.ing.unimore.it
  rank      : 3 (local_rank: 3)
  exitcode  : -9 (pid: 2845247)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 2845247
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-25_18:53:54
  host      : ajeje.ing.unimore.it
  rank      : 2 (local_rank: 2)
  exitcode  : -9 (pid: 2845246)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 2845246
========================================================
slurmstepd: error: Detected 2 oom_kill events in StepId=2396649.batch. Some of the step tasks have been OOM Killed.
